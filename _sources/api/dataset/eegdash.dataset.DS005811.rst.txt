..
   This documentation page is generated during the Sphinx build.
   The underlying code is manually maintained and not autogenerated.

eegdash.dataset.DS005811
========================

NOD-EEG (OpenNeuro ``ds005811``). Access recordings and metadata through EEGDash.

**Citation:** Guohao Zhang, Ming Zhou, Shaohua Tang, Shuyi Zhen, Zheng Li, Zonglei Zhen (—). *NOD-EEG*. `10.18112/openneuro.ds005811.v1.0.8 <https://doi.org/10.18112/openneuro.ds005811.v1.0.8>`__

.. rst-class:: sd-badges

:bdg-primary:`Modality: eeg` :bdg-info:`Tasks: 1` :bdg-secondary:`Subjects: 19` :bdg-secondary:`Recordings: 448`

.. rst-class:: sd-badges

:bdg-success:`License: CC0` :bdg-warning:`Source: openneuro` :bdg-info:`Citations: —`

Dataset Information
-------------------

.. list-table::
   :widths: 25 75
   :header-rows: 0

   * - Dataset ID
     - ``DS005811``
   * - Title
     - NOD-EEG
   * - Year
     - —
   * - Authors
     - Guohao Zhang, Ming Zhou, Shaohua Tang, Shuyi Zhen, Zheng Li, Zonglei Zhen
   * - License
     - CC0
   * - Citation / DOI
     - `doi:10.18112/openneuro.ds005811.v1.0.8 <https://doi.org/10.18112/openneuro.ds005811.v1.0.8>`__
   * - Source links
     - `OpenNeuro <https://openneuro.org/datasets/ds005811>`__ | `NeMAR <https://nemar.org/dataexplorer/detail?dataset_id=ds005811>`__ | `Source URL <https://openneuro.org/datasets/ds005811>`__

.. dropdown:: Copy-paste BibTeX
   :class-container: sd-shadow-sm
   :class-title: sd-bg-light

   .. code-block:: bibtex

      @dataset{ds005811,
        title = {NOD-EEG},
        author = {Guohao Zhang and Ming Zhou and Shaohua Tang and Shuyi Zhen and Zheng Li and Zonglei Zhen},
        doi = {10.18112/openneuro.ds005811.v1.0.8},
        url = {https://doi.org/10.18112/openneuro.ds005811.v1.0.8},
      }

.. admonition:: Found an issue with this dataset?
   :class: tip

   If you encounter any problems with this dataset (missing files, incorrect metadata,
   loading errors, etc.), please let us know!

   .. button-link:: https://github.com/eegdash/EEGDash/issues/new?title=%5BDataset%5D%20Issue%20with%20DS005811&body=%23%23%20Dataset%0A%0A-%20%2A%2ADataset%20ID%3A%2A%2A%20DS005811%0A-%20%2A%2ATitle%3A%2A%2A%20NOD-EEG%0A%0A%23%23%20Issue%20Description%0A%0APlease%20describe%20the%20issue%20you%20encountered%20with%20this%20dataset%3A%0A%0A%23%23%20Steps%20to%20Reproduce%0A%0A1.%20%0A2.%20%0A3.%20%0A%0A%23%23%20Expected%20Behavior%0A%0A%0A%23%23%20Additional%20Context%0A%0A&labels=dataset
      :color: primary
      :outline:

      Report an Issue on GitHub

Description
-----------


**Summary**

The human brain can rapidly recognize meaningful objects from natural scenes encountered in everyday life. Neuroimaging with large-scale naturalistic stimuli is increasingly employed to elucidate these neural mechanisms of object recognition across these rich and daily natural scenes. However, most existing large-scale neuroimaging datasets with naturalistic stimuli primarily rely on functional magnetic resonance imaging (fMRI), which provides high spatial resolution to characterize spatial representation patterns but is limited in capturing the temporal dynamics inherent in visual cognitive processing.
To address this limitation, we extended our previously collected Natural Object Dataset-fMRI (NOD-fMRI) by collecting both magnetoencephalography (MEG) and electroencephalography (EEG) data from the same subjects while viewing the same set of naturalistic stimuli. As a result, the NOD uniquely integrates three different modalities—fMRI, MEG, and EEG—thus offering promising avenues to examine brain activity induced by naturalistic stimuli with both high spatial and high temporal resolutions. Additionally, the NOD encompasses a diverse array of naturalistic stimuli and a broader subject pool, enabling researchers to explore differences in neural activation patterns across both stimuli and subjects.
We anticipate that the NOD dataset will serve as a valuable resource for advancing our understanding of the cognitive and neural mechanisms underlying object recognition.

**The MEG data's accession number is `ds005810`.**



.. dropdown:: View full README
   :class-container: sd-shadow-sm

   
   **Summary**
   
   The human brain can rapidly recognize meaningful objects from natural scenes encountered in everyday life. Neuroimaging with large-scale naturalistic stimuli is increasingly employed to elucidate these neural mechanisms of object recognition across these rich and daily natural scenes. However, most existing large-scale neuroimaging datasets with naturalistic stimuli primarily rely on functional magnetic resonance imaging (fMRI), which provides high spatial resolution to characterize spatial representation patterns but is limited in capturing the temporal dynamics inherent in visual cognitive processing.
   To address this limitation, we extended our previously collected Natural Object Dataset-fMRI (NOD-fMRI) by collecting both magnetoencephalography (MEG) and electroencephalography (EEG) data from the same subjects while viewing the same set of naturalistic stimuli. As a result, the NOD uniquely integrates three different modalities—fMRI, MEG, and EEG—thus offering promising avenues to examine brain activity induced by naturalistic stimuli with both high spatial and high temporal resolutions. Additionally, the NOD encompasses a diverse array of naturalistic stimuli and a broader subject pool, enabling researchers to explore differences in neural activation patterns across both stimuli and subjects.
   We anticipate that the NOD dataset will serve as a valuable resource for advancing our understanding of the cognitive and neural mechanisms underlying object recognition.
   
   **The MEG data's accession number is `ds005810`.**
   
   
   **Data Records**
   
   
   **Directory Structure**
   
   The raw data from each subject are stored in the `sub-subID` directory, while preprocessed data and epoch data are stored in the following directories:
   - **Preprocessed Data:** `derivatives/preprocessed/raw`
   - **Epoch Data:** `derivatives/preprocessed/epochs`
   
   **Stimulus Images**
   
   The stimulus images used for MEG and EEG are identical and are stored in the `stimuli/ImageNet` directory. Images within this folder are named in the `synsetID_imageID.JPEG` Where:
   - `synsetID` is the ILSVRC category information.
   - `imageID` is the unique number for the image within that category.
   The image metadata, including category information, is available in the table files under the `stimuli/metadata` directory.
   
   **Raw Data**
   
   Raw EEG data are stored in BIDS format. Each subject's directory contains multiple session folders, designated as `ses-sesID`. Comprehensive trial information for each subject is documented in the file: `derivatives/detailed_events/sub-subID_events.csv` Where each row corresponds to a trial, and each column contains metadata for that trial, including the session and run number, category information of the stimuli, and subject response.
   
   **Preprocessed Data**
   
   The full time series data of preprocessed data are archived in the `derivatives/raw` directory, named as: `sub-subID_ses-sesID_task-ImageNet_run-runID_eeg_clean.fif`. The epoch data derived from preprocessed data are stored within the `derivatives/epochs` directory. In this directory, all data for each subject are concatenated into a single file, labeled as: `sub-subID_epo.fif`
   The trial information within each subject's epochs data can be accessed via the metadata of the epochs data, which are aligned with the content of the subject's `sub-subID_events.csv` file.


Highlights
----------

.. grid:: 1 2 3 3
   :gutter: 2

   .. grid-item-card:: Subjects & recordings
      :class-card: sd-border-1

      - Subjects: 19
      - Recordings: 448
      - Tasks: 1

   .. grid-item-card:: Channels & sampling rate
      :class-card: sd-border-1

      - Channels: 62 (448), 64 (440), 66 (8)
      - Sampling rate (Hz): 500.0 (576), 1000.0 (320)
      - Duration (hours): 0.0

   .. grid-item-card:: Tags
      :class-card: sd-border-1

      - Pathology: Healthy
      - Modality: Visual
      - Type: Perception

   .. grid-item-card:: Files & format
      :class-card: sd-border-1

      - Size on disk: 24.2 GB
      - File count: 448
      - Format: BIDS

   .. grid-item-card:: License & citation
      :class-card: sd-border-1

      - License: CC0
      - DOI: doi:10.18112/openneuro.ds005811.v1.0.8

   .. grid-item-card:: Provenance
      :class-card: sd-border-1

      - Source: openneuro
      - OpenNeuro: `ds005811 <https://openneuro.org/datasets/ds005811>`__
      - NeMAR: `ds005811 <https://nemar.org/dataexplorer/detail?dataset_id=ds005811>`__

Quickstart
----------

**Install**

.. code-block:: bash

    pip install eegdash

**Access the data**

.. code-block:: python

    from eegdash.dataset import DS005811

    dataset = DS005811(cache_dir="./data")
    # Get the raw object of the first recording
    raw = dataset.datasets[0].raw
    print(raw.info)

**Filter/query**

.. tab-set::

   .. tab-item:: Basic

      .. code-block:: python

         dataset = DS005811(cache_dir="./data", subject="01")

   .. tab-item:: Advanced

      .. code-block:: python

         dataset = DS005811(
             cache_dir="./data",
             query={"subject": {"$in": ["01", "02"]}},
         )


Quality & caveats
-----------------

- No dataset-specific caveats are listed in the available metadata.

API
---

.. currentmodule:: eegdash.dataset

.. autoclass:: eegdash.dataset.DS005811
   :members: __init__, save
   :show-inheritance:
   :member-order: bysource


See Also
--------

* :class:`eegdash.dataset.EEGDashDataset`
* :mod:`eegdash.dataset`
* `OpenNeuro dataset page <https://openneuro.org/datasets/ds005811>`__
* `NeMAR dataset page <https://nemar.org/dataexplorer/detail?dataset_id=ds005811>`__

