..
   This documentation page is generated during the Sphinx build.
   The underlying code is manually maintained and not autogenerated.

eegdash.dataset.DS005407
========================

The effect of speech masking on the subcortical response to speech (OpenNeuro ``ds005407``). Access recordings and metadata through EEGDash.

**Citation:** Melissa J. Polonenko, Ross K. Maddox (2024). *The effect of speech masking on the subcortical response to speech*. `10.18112/openneuro.ds005407.v1.0.0 <https://doi.org/10.18112/openneuro.ds005407.v1.0.0>`__

.. rst-class:: sd-badges

:bdg-primary:`Modality: eeg` :bdg-info:`Tasks: 1` :bdg-secondary:`Subjects: 25` :bdg-secondary:`Recordings: 29`

.. rst-class:: sd-badges

:bdg-success:`License: CC0` :bdg-warning:`Source: openneuro` :bdg-info:`Citations: —`

Dataset Information
-------------------

.. list-table::
   :widths: 25 75
   :header-rows: 0

   * - Dataset ID
     - ``DS005407``
   * - Title
     - The effect of speech masking on the subcortical response to speech
   * - Year
     - 2024
   * - Authors
     - Melissa J. Polonenko, Ross K. Maddox
   * - License
     - CC0
   * - Citation / DOI
     - `doi:10.18112/openneuro.ds005407.v1.0.0 <https://doi.org/10.18112/openneuro.ds005407.v1.0.0>`__
   * - Source links
     - `OpenNeuro <https://openneuro.org/datasets/ds005407>`__ | `NeMAR <https://nemar.org/dataexplorer/detail?dataset_id=ds005407>`__ | `Source URL <https://openneuro.org/datasets/ds005407>`__

.. dropdown:: Copy-paste BibTeX
   :class-container: sd-shadow-sm
   :class-title: sd-bg-light

   .. code-block:: bibtex

      @dataset{ds005407,
        title = {The effect of speech masking on the subcortical response to speech},
        author = {Melissa J. Polonenko and Ross K. Maddox},
        doi = {10.18112/openneuro.ds005407.v1.0.0},
        url = {https://doi.org/10.18112/openneuro.ds005407.v1.0.0},
      }

.. admonition:: Found an issue with this dataset?
   :class: tip

   If you encounter any problems with this dataset (missing files, incorrect metadata,
   loading errors, etc.), please let us know!

   .. button-link:: https://github.com/eegdash/EEGDash/issues/new?title=%5BDataset%5D%20Issue%20with%20DS005407&body=%23%23%20Dataset%0A%0A-%20%2A%2ADataset%20ID%3A%2A%2A%20DS005407%0A-%20%2A%2ATitle%3A%2A%2A%20The%20effect%20of%20speech%20masking%20on%20the%20subcortical%20response%20to%20speech%0A%0A%23%23%20Issue%20Description%0A%0APlease%20describe%20the%20issue%20you%20encountered%20with%20this%20dataset%3A%0A%0A%23%23%20Steps%20to%20Reproduce%0A%0A1.%20%0A2.%20%0A3.%20%0A%0A%23%23%20Expected%20Behavior%0A%0A%0A%23%23%20Additional%20Context%0A%0A&labels=dataset
      :color: primary
      :outline:

      Report an Issue on GitHub

Description
-----------


**README**


**Details related to access to the data**

Please contact the following authors for further information:
    Melissa Polonenko(email: mpolonen@umn.edu)
    Ross Maddox (email: rkmaddox@med.umich.edu)


.. dropdown:: View full README
   :class-container: sd-shadow-sm

   
   **README**
   
   
   **Details related to access to the data**
   
   Please contact the following authors for further information:
       Melissa Polonenko(email: mpolonen@umn.edu)
       Ross Maddox (email: rkmaddox@med.umich.edu)
   
   **Overview**
   
   This is the "peaky_snr" dataset for the paper
   Polonenko MJ & Maddox RK (2024), with citation listed below.
   BioRxiv: The effect of speech masking on the subcortical response to speech
   Auditory brainstem responses (ABRs) were derived to continuous peaky speech
   from between one up to five simultaneously presented talkers and from clicks.
   Data was collected from June to July 2021.
   Goal: To better understand masking’s effects on the subcortical neural encoding
   of naturally uttered speech in human listeners.
   To do this we leveraged our recently developed method for determining the
   auditory brainstem response (ABR) to speech (Polonenko and Maddox, 2021).
   Whereas our previous work was aimed at encoding of single talkers, here we
   determined the ABR to speech in quiet as well as in the presence of varying
   numbers of other talkers.
   The details of the experiment can be found at Polonenko & Maddox (2024).
   Stimuli:
       1) randomized click trains at an average rate of 40 Hz,
       60 x 10 s trials for a total of 10 minutes;
       2) peaky speech for up to 5 male narrators. 30 minutes of each SNR
       (clean, 0 dB, -3 dB, -6 dB), corresponding to 1, 2, 3, and 5 talkers
       presented simultaneously, each set to 65 dB.
       NOTE: files for each story were completely randomized. Random combinations
       were created so that each story was equally represented in the data.
   The code for stimulus preprocessing and EEG analysis is available on Github:
       https://github.com/polonenkolab/peaky_snr
   
   **Format**
   
   The dataset is formatted according to the EEG Brain Imaging Data Structure. It
   includes EEG recording from participant 01 to 25 in raw brainvision format
   (3 files: .eeg, .vhdr, .vmrk) and stimuli files in format of .hdf5. The stimuli
   files contain the audio ('audio'), and regressors for the deconvolution
   ('pinds' are the pulse indices, 'anm' is an auditory nerve model regressor,
    which was used during analyses but was not included as part of the article).
   Generally, you can find detailed event data in the .tsv files and descriptions
   in the accompanying .json files. Raw eeg files are provided in the Brain
   Products format.
   
   **Participants**
   
   25 participants, mean ± SD age of 23.4 ± 5.5 years (19-37 years)
   Inclusion criteria:
       1) Age between 18-40 years
       2) Normal hearing: audiometric thresholds 20 dB HL or better from 500 to 8000 Hz
       3) Speak English as their primary language
   Please see participants.tsv for more information.
   
   **Apparatus**
   
   Participants sat in a darkened sound-isolating booth and rested or watched
   silent videos with closed captioning. Stimuli were presented at an average level
   of 65 dB SPL (per story; total for 5 talkers = 71 dB) and a sampling rate of
   48 kHz through ER-2 insert earphones plugged into an RME Babyface Pro digital
   sound card. Custom python scripts using expyfun were used to control the
   experiment and stimulus presentation.
   
   **Details about the experiment**
   
   For a detailed description of the task, see Polonenko & Maddox (2024) and the
   supplied `task-peaky_snr_eeg.json` file. The 4 SNR speech conditions and the
   story tokens were randomized. This means that the participant would not be able
   to follow the stories. For clicks the trials were not randomized
   (already random clicks).
   Trigger onset times in the tsv files have already been corrected for the tubing
   delay of the insert earphones (but not in the events of the raw files).
   Triggers with values of "1" were recorded to the onset of the 10 s audio, and
   shortly after triggers with values of "4" or "8" were stamped to indicate info
   about the trial. This was done by converting the decimal trial number to bits,
   denoted b, then calculating 2 ** (b + 2). We've specified these trial triggers
   and more metadata of the events in each of the '*_eeg_events.tsv" file, which
   is sufficient to know which trial corresponded to which type of stimulus
   (clicks or speech), snr, and which files of which stories were presented.
   e.g., alice_000_peaky_diotic_regress.hdf5 for the first file of the story
   called 'alice' (Alice in Wonderland).


Highlights
----------

.. grid:: 1 2 3 3
   :gutter: 2

   .. grid-item-card:: Subjects & recordings
      :class-card: sd-border-1

      - Subjects: 25
      - Recordings: 29
      - Tasks: 1

   .. grid-item-card:: Channels & sampling rate
      :class-card: sd-border-1

      - Channels: 2
      - Sampling rate (Hz): 10000.0
      - Duration (hours): 0.0

   .. grid-item-card:: Tags
      :class-card: sd-border-1

      - Pathology: Healthy
      - Modality: Auditory
      - Type: Perception

   .. grid-item-card:: Files & format
      :class-card: sd-border-1

      - Size on disk: 37.8 GB
      - File count: 29
      - Format: BIDS

   .. grid-item-card:: License & citation
      :class-card: sd-border-1

      - License: CC0
      - DOI: doi:10.18112/openneuro.ds005407.v1.0.0

   .. grid-item-card:: Provenance
      :class-card: sd-border-1

      - Source: openneuro
      - OpenNeuro: `ds005407 <https://openneuro.org/datasets/ds005407>`__
      - NeMAR: `ds005407 <https://nemar.org/dataexplorer/detail?dataset_id=ds005407>`__

Quickstart
----------

**Install**

.. code-block:: bash

    pip install eegdash

**Access the data**

.. code-block:: python

    from eegdash.dataset import DS005407

    dataset = DS005407(cache_dir="./data")
    # Get the raw object of the first recording
    raw = dataset.datasets[0].raw
    print(raw.info)

**Filter/query**

.. tab-set::

   .. tab-item:: Basic

      .. code-block:: python

         dataset = DS005407(cache_dir="./data", subject="01")

   .. tab-item:: Advanced

      .. code-block:: python

         dataset = DS005407(
             cache_dir="./data",
             query={"subject": {"$in": ["01", "02"]}},
         )


Quality & caveats
-----------------

- No dataset-specific caveats are listed in the available metadata.

API
---

.. currentmodule:: eegdash.dataset

.. autoclass:: eegdash.dataset.DS005407
   :members: __init__, save
   :show-inheritance:
   :member-order: bysource


See Also
--------

* :class:`eegdash.dataset.EEGDashDataset`
* :mod:`eegdash.dataset`
* `OpenNeuro dataset page <https://openneuro.org/datasets/ds005407>`__
* `NeMAR dataset page <https://nemar.org/dataexplorer/detail?dataset_id=ds005407>`__

