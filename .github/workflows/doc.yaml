name: docs
concurrency:
  group: ${{ github.workflow }}-${{ github.event.number }}-${{ github.event.ref }}
  cancel-in-progress: true
on:
  push:
    branches:
      - "main"
  pull_request:
    branches:
      - '*' # all branches, including forks

permissions:
  contents: write
  pull-requests: write

jobs:
  docs:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ "ubuntu-latest" ]
        python-version: ["3.11"]
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Configure dataset cache paths
        id: cache-paths
        shell: python
        run: |
          import os
          from pathlib import Path

          home = Path.home()
          workspace = Path(os.environ["GITHUB_WORKSPACE"]).resolve()
          candidates = {
              "primary": home / "eegdash_cache",
              "home_dot": home / ".eegdash_cache",
              "workspace": workspace / ".eegdash_cache",
              "mne_data": home / "mne_data",
          }

          for path in candidates.values():
              path.mkdir(parents=True, exist_ok=True)

          with open(os.environ["GITHUB_ENV"], "a", encoding="utf-8") as env_file:
              env_file.write(f"EEGDASH_CACHE_DIR={candidates['primary']}\n")
              env_file.write(f"MNE_DATA={candidates['primary']}\n")

          with open(os.environ["GITHUB_OUTPUT"], "a", encoding="utf-8") as output:
              for key, path in candidates.items():
                  output.write(f"{key}={path}\n")

      - name: Install dependencies
        run: |
          python -m pip install uv
          uv venv
          uv pip install -e .[all]

      - name: Activate virtualenv
        run: |
          . .venv/bin/activate
          echo PATH=$PATH >> $GITHUB_ENV

      - name: Restore Data Caches (pull_request)
        if: github.event_name == 'pull_request'
        id: cache-data-restore
        uses: actions/cache@v4
        with:
          path: |
            ${{ steps.cache-paths.outputs.primary }}
            ${{ steps.cache-paths.outputs.home_dot }}
            ${{ steps.cache-paths.outputs.workspace }}
            ${{ steps.cache-paths.outputs.mne_data }}
          # Cache includes dataset manifest hash so new datasets invalidate once automatically.
          key: ${{ runner.os }}-data-${{ github.head_ref || github.ref_name }}-${{ hashFiles('consolidated/datasets_consolidated.json') }}-v2
          restore-keys: |
            ${{ runner.os }}-data-${{ github.base_ref || github.ref_name }}-${{ hashFiles('consolidated/datasets_consolidated.json') }}-
            ${{ runner.os }}-data-develop-${{ hashFiles('consolidated/datasets_consolidated.json') }}-
            ${{ runner.os }}-data-main-${{ hashFiles('consolidated/datasets_consolidated.json') }}-
            ${{ runner.os }}-data-${{ github.base_ref || github.ref_name }}-
            ${{ runner.os }}-data-develop-
            ${{ runner.os }}-data-main-
            ${{ runner.os }}-data-
          lookup-only: true

      - name: Create/Restore Data Caches (push)
        if: github.event_name != 'pull_request'
        id: cache-data
        uses: actions/cache@v4
        with:
          path: |
            ${{ steps.cache-paths.outputs.primary }}
            ${{ steps.cache-paths.outputs.home_dot }}
            ${{ steps.cache-paths.outputs.workspace }}
            ${{ steps.cache-paths.outputs.mne_data }}
          # Cache includes dataset manifest hash so new datasets invalidate once automatically.
          key: ${{ runner.os }}-data-${{ github.head_ref || github.ref_name }}-${{ hashFiles('consolidated/datasets_consolidated.json') }}-v2
          restore-keys: |
            ${{ runner.os }}-data-${{ github.base_ref || github.ref_name }}-${{ hashFiles('consolidated/datasets_consolidated.json') }}-
            ${{ runner.os }}-data-develop-${{ hashFiles('consolidated/datasets_consolidated.json') }}-
            ${{ runner.os }}-data-main-${{ hashFiles('consolidated/datasets_consolidated.json') }}-
            ${{ runner.os }}-data-${{ github.base_ref || github.ref_name }}-
            ${{ runner.os }}-data-develop-
            ${{ runner.os }}-data-main-
            ${{ runner.os }}-data-

      - name: Create Docs
        run: |
          cd docs
          uv run make html

      # Upload documentation as artifact for all builds
      - name: Upload documentation artifact
        uses: actions/upload-artifact@v4
        with:
          name: documentation-html
          path: ./docs/build/html
          retention-days: 14

      # Deploy PR preview to surge.sh (optional - requires SURGE_TOKEN secret)
      - name: Deploy PR Preview
        if: github.event_name == 'pull_request'
        id: deploy-preview
        continue-on-error: true
        env:
          SURGE_TOKEN: ${{ secrets.SURGE_TOKEN }}
        run: |
          if [ -z "$SURGE_TOKEN" ]; then
            echo "SURGE_TOKEN not configured, skipping live preview deployment"
            exit 0
          fi
          npm install -g surge
          DEPLOY_DOMAIN="eegdash-pr-${{ github.event.pull_request.number }}.surge.sh"
          surge ./docs/build/html $DEPLOY_DOMAIN --token $SURGE_TOKEN
          echo "preview_url=https://$DEPLOY_DOMAIN" >> $GITHUB_OUTPUT

      # Comment on PR with preview link
      - name: Comment PR with Preview Link
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const previewUrl = '${{ steps.deploy-preview.outputs.preview_url }}' || '';
            const artifactUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            const surgeSuccess = '${{ steps.deploy-preview.outcome }}' === 'success';

            let body = `## ðŸ“š Documentation Preview\n\n`;

            if (surgeSuccess && previewUrl) {
              body += `| Resource | Link |\n`;
              body += `|----------|------|\n`;
              body += `| ðŸŒ **Live Preview** | [${previewUrl}](${previewUrl}) |\n`;
              body += `| ðŸ“¦ Download Artifact | [View Workflow Run](${artifactUrl}) |\n\n`;
              body += `> This preview will be available for 14 days. The live preview updates with each push to this PR.`;
            } else {
              body += `ðŸ“¦ **[Download Documentation Artifact](${artifactUrl})**\n\n`;
              body += `> Download the \`documentation-html\` artifact from the workflow run to view the docs locally.\n\n`;
              body += `ðŸ’¡ *To enable live previews, add a \`SURGE_TOKEN\` secret to this repository. See [surge.sh](https://surge.sh) for setup instructions.*`;
            }

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('Documentation Preview')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }

      # Deploy the docs to the gh-pages branch (main only)
      - name: Deploy to GitHub Pages
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./docs/build/html
          cname: eegdash.org
