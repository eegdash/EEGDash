..
   This documentation page is generated during the Sphinx build.
   The underlying code is manually maintained and not autogenerated.

eegdash.dataset.DS006735
========================

Chimeric music reveals an interaction of pitch and time in electrophysiological signatures of music encoding (OpenNeuro ``ds006735``). Access recordings and metadata through EEGDash.

**Citation:** Tong Shan, Edmund C. Lalor, Ross K. Maddox (2024). *Chimeric music reveals an interaction of pitch and time in electrophysiological signatures of music encoding*. `10.18112/openneuro.ds006735.v1.0.4 <https://doi.org/10.18112/openneuro.ds006735.v1.0.4>`__

.. rst-class:: sd-badges

:bdg-primary:`Modality: eeg` :bdg-info:`Tasks: 1` :bdg-secondary:`Subjects: 27` :bdg-secondary:`Recordings: 27`

.. rst-class:: sd-badges

:bdg-success:`License: CC0` :bdg-warning:`Source: openneuro` :bdg-info:`Citations: —`

Dataset Information
-------------------

.. list-table::
   :widths: 25 75
   :header-rows: 0

   * - Dataset ID
     - ``DS006735``
   * - Title
     - Chimeric music reveals an interaction of pitch and time in electrophysiological signatures of music encoding
   * - Year
     - 2024
   * - Authors
     - Tong Shan, Edmund C. Lalor, Ross K. Maddox
   * - License
     - CC0
   * - Citation / DOI
     - `doi:10.18112/openneuro.ds006735.v1.0.4 <https://doi.org/10.18112/openneuro.ds006735.v1.0.4>`__
   * - Source links
     - `OpenNeuro <https://openneuro.org/datasets/ds006735>`__ | `NeMAR <https://nemar.org/dataexplorer/detail?dataset_id=ds006735>`__ | `Source URL <https://openneuro.org/datasets/ds006735>`__

.. dropdown:: Copy-paste BibTeX
   :class-container: sd-shadow-sm
   :class-title: sd-bg-light

   .. code-block:: bibtex

      @dataset{ds006735,
        title = {Chimeric music reveals an interaction of pitch and time in electrophysiological signatures of music encoding},
        author = {Tong Shan and Edmund C. Lalor and Ross K. Maddox},
        doi = {10.18112/openneuro.ds006735.v1.0.4},
        url = {https://doi.org/10.18112/openneuro.ds006735.v1.0.4},
      }

.. admonition:: Found an issue with this dataset?
   :class: tip

   If you encounter any problems with this dataset (missing files, incorrect metadata,
   loading errors, etc.), please let us know!

   .. button-link:: https://github.com/eegdash/EEGDash/issues/new?title=%5BDataset%5D%20Issue%20with%20DS006735&body=%23%23%20Dataset%0A%0A-%20%2A%2ADataset%20ID%3A%2A%2A%20DS006735%0A-%20%2A%2ATitle%3A%2A%2A%20Chimeric%20music%20reveals%20an%20interaction%20of%20pitch%20and%20time%20in%20electrophysiological%20signatures%20of%20music%20encoding%0A%0A%23%23%20Issue%20Description%0A%0APlease%20describe%20the%20issue%20you%20encountered%20with%20this%20dataset%3A%0A%0A%23%23%20Steps%20to%20Reproduce%0A%0A1.%20%0A2.%20%0A3.%20%0A%0A%23%23%20Expected%20Behavior%0A%0A%0A%23%23%20Additional%20Context%0A%0A&labels=dataset
      :color: primary
      :outline:

      Report an Issue on GitHub

Description
-----------


**Details related to access to the data**

Please contact the following authors for further information:
Tong Shan (email: tongshan@stanford.edu)
Ross K. Maddox (email: rkmaddox@med.umich.edu)

**Overview**

This study examines pitch-time interactions in music processing by introducing “chimeric music,” which pairs two distinct melodies, and exchanges their pitch contours and note onset-times to create two new melodies, thereby distorting musical pattern while maintaining the marginal statistics of the original pieces’ pitch and temporal sequences.

.. dropdown:: View full README
   :class-container: sd-shadow-sm

   
   **Details related to access to the data**
   
   Please contact the following authors for further information:
   Tong Shan (email: tongshan@stanford.edu)
   Ross K. Maddox (email: rkmaddox@med.umich.edu)
   
   **Overview**
   
   This study examines pitch-time interactions in music processing by introducing “chimeric music,” which pairs two distinct melodies, and exchanges their pitch contours and note onset-times to create two new melodies, thereby distorting musical pattern while maintaining the marginal statistics of the original pieces’ pitch and temporal sequences.
   Data collected from Sep to Nov, 2023.
   The details of the experiment can be found at Shan et al. (2024). There were two phases in this experiment. For the first phase, ten trials of one-minute clicks were presented to the subjects. For the second phase, the 2 types of monophonic music (original and chimeric) clips were presented. There were 33 trials for each type with shuffled order. Between trials, there was a 0.5 s pause.
   The code for analysis for this study can be found in GitHub repo (https://github.com/maddoxlab/Chimeric_music).
   
   **Format**
   
   This dataset is formatted according to the EEG Brain Imaging Data Structure. It includes EEG recording from subject 001 to subject 027 in raw brainvision format (including .eeg, .vhdr, and .vmrk triplet).
   
   **Subjects**
   
   27 subjects participated in this study.
   
   **Subject inclusion criteria**
   
   Age between 18-40.
   Normal hearing: audiometric thresholds of 20 dB HL or better from 500 to 8000 Hz.
   Speak English as their primary language.
   Self-reported normal or correctable to normal vision.
   Twenty-seven participants participated in this experiment with an age of 22.9 ± 3.9 (mean ± STD) years.
   
   **Apparatus**
   
   Subjects were seated in a sound-isolating booth on a chair in front of a 24-inch BenQ monitor with a viewing distance of approximately 60 cm. Stimuli were presented at an average level of 60 dB SPL and a sampling rate of 48000 Hz through ER-2 insert earphones plugged into an RME Babyface Pro digital sound card. The stimulus presentation for the experiment was controlled by a python script using a custom package, expyfun.
   Following the experimental session, participants completed a self-reported musicianship questionnaire (adapted from Whiteford et al, 2025). The questionnaire is included in this repository.


Highlights
----------

.. grid:: 1 2 3 3
   :gutter: 2

   .. grid-item-card:: Subjects & recordings
      :class-card: sd-border-1

      - Subjects: 27
      - Recordings: 27
      - Tasks: 1

   .. grid-item-card:: Channels & sampling rate
      :class-card: sd-border-1

      - Channels: 36 (48), 63 (4), 34 (2)
      - Sampling rate (Hz): 10000.0
      - Duration (hours): 0.0

   .. grid-item-card:: Tags
      :class-card: sd-border-1

      - Pathology: Healthy
      - Modality: Auditory
      - Type: Perception

   .. grid-item-card:: Files & format
      :class-card: sd-border-1

      - Size on disk: 192.9 GB
      - File count: 27
      - Format: BIDS

   .. grid-item-card:: License & citation
      :class-card: sd-border-1

      - License: CC0
      - DOI: doi:10.18112/openneuro.ds006735.v1.0.4

   .. grid-item-card:: Provenance
      :class-card: sd-border-1

      - Source: openneuro
      - OpenNeuro: `ds006735 <https://openneuro.org/datasets/ds006735>`__
      - NeMAR: `ds006735 <https://nemar.org/dataexplorer/detail?dataset_id=ds006735>`__

Quickstart
----------

**Install**

.. code-block:: bash

    pip install eegdash

**Access the data**

.. code-block:: python

    from eegdash.dataset import DS006735

    dataset = DS006735(cache_dir="./data")
    # Get the raw object of the first recording
    raw = dataset.datasets[0].raw
    print(raw.info)

**Filter/query**

.. tab-set::

   .. tab-item:: Basic

      .. code-block:: python

         dataset = DS006735(cache_dir="./data", subject="01")

   .. tab-item:: Advanced

      .. code-block:: python

         dataset = DS006735(
             cache_dir="./data",
             query={"subject": {"$in": ["01", "02"]}},
         )


Quality & caveats
-----------------

- No dataset-specific caveats are listed in the available metadata.

API
---

.. currentmodule:: eegdash.dataset

.. autoclass:: eegdash.dataset.DS006735
   :members: __init__, save
   :show-inheritance:
   :member-order: bysource


See Also
--------

* :class:`eegdash.dataset.EEGDashDataset`
* :mod:`eegdash.dataset`
* `OpenNeuro dataset page <https://openneuro.org/datasets/ds006735>`__
* `NeMAR dataset page <https://nemar.org/dataexplorer/detail?dataset_id=ds006735>`__

