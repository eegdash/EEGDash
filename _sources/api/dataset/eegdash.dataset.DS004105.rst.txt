..
   This documentation page is generated during the Sphinx build.
   The underlying code is manually maintained and not autogenerated.

eegdash.dataset.DS004105
========================

BCIT Auditory Cueing (OpenNeuro ``ds004105``). Access recordings and metadata through EEGDash.

**Citation:** Javier Garcia (data), Justin Brooks (data), Scott Kerick (data), Tony Johnson (data and curation), Tim Mullen (data), Jean Vettel (data), Jonathan Touryan (curation), Kay Robbins (curation) (20). *BCIT Auditory Cueing*. `10.18112/openneuro.ds004105.v1.0.0 <https://doi.org/10.18112/openneuro.ds004105.v1.0.0>`__

.. rst-class:: sd-badges

:bdg-primary:`Modality: eeg` :bdg-info:`Tasks: 1` :bdg-secondary:`Subjects: 17` :bdg-secondary:`Recordings: 34`

.. rst-class:: sd-badges

:bdg-success:`License: CC0` :bdg-warning:`Source: openneuro` :bdg-info:`Citations: 0.0`

Dataset Information
-------------------

.. list-table::
   :widths: 25 75
   :header-rows: 0

   * - Dataset ID
     - ``DS004105``
   * - Title
     - BCIT Auditory Cueing
   * - Year
     - 20
   * - Authors
     - Javier Garcia (data), Justin Brooks (data), Scott Kerick (data), Tony Johnson (data and curation), Tim Mullen (data), Jean Vettel (data), Jonathan Touryan (curation), Kay Robbins (curation)
   * - License
     - CC0
   * - Citation / DOI
     - `doi:10.18112/openneuro.ds004105.v1.0.0 <https://doi.org/10.18112/openneuro.ds004105.v1.0.0>`__
   * - Source links
     - `OpenNeuro <https://openneuro.org/datasets/ds004105>`__ | `NeMAR <https://nemar.org/dataexplorer/detail?dataset_id=ds004105>`__ | `Source URL <https://openneuro.org/datasets/ds004105>`__

.. dropdown:: Copy-paste BibTeX
   :class-container: sd-shadow-sm
   :class-title: sd-bg-light

   .. code-block:: bibtex

      @dataset{ds004105,
        title = {BCIT Auditory Cueing},
        author = {Javier Garcia (data) and Justin Brooks (data) and Scott Kerick (data) and Tony Johnson (data and curation) and Tim Mullen (data) and Jean Vettel (data) and Jonathan Touryan (curation) and Kay Robbins (curation)},
        doi = {10.18112/openneuro.ds004105.v1.0.0},
        url = {https://doi.org/10.18112/openneuro.ds004105.v1.0.0},
      }

.. admonition:: Found an issue with this dataset?
   :class: tip

   If you encounter any problems with this dataset (missing files, incorrect metadata,
   loading errors, etc.), please let us know!

   .. button-link:: https://github.com/eegdash/EEGDash/issues/new?title=%5BDataset%5D%20Issue%20with%20DS004105&body=%23%23%20Dataset%0A%0A-%20%2A%2ADataset%20ID%3A%2A%2A%20DS004105%0A-%20%2A%2ATitle%3A%2A%2A%20BCIT%20Auditory%20Cueing%0A%0A%23%23%20Issue%20Description%0A%0APlease%20describe%20the%20issue%20you%20encountered%20with%20this%20dataset%3A%0A%0A%23%23%20Steps%20to%20Reproduce%0A%0A1.%20%0A2.%20%0A3.%20%0A%0A%23%23%20Expected%20Behavior%0A%0A%0A%23%23%20Additional%20Context%0A%0A&labels=dataset
      :color: primary
      :outline:

      Report an Issue on GitHub

Description
-----------


**Introduction**

**Overview:** Subjects in the Auditory Cueing study performed a long-duration simulated driving task with
perturbations and audio stimuli in a visually sparse environment.
The purpose of this effort was to supplement and extend the related driving research to collect
prolonged time-on-task measurements of subjects performing a driving task in a simulated environment
in order to assess fatigue-based performance through novel biomarkers.
Similar to the Baseline Driving study, the Auditory Cueing study was intended to identify periods
of driver fatigue via predictive algorithms formulated from the analysis of driver EEG data,

.. dropdown:: View full README
   :class-container: sd-shadow-sm

   
   **Introduction**
   
   **Overview:** Subjects in the Auditory Cueing study performed a long-duration simulated driving task with
   perturbations and audio stimuli in a visually sparse environment.
   The purpose of this effort was to supplement and extend the related driving research to collect
   prolonged time-on-task measurements of subjects performing a driving task in a simulated environment
   in order to assess fatigue-based performance through novel biomarkers.
   Similar to the Baseline Driving study, the Auditory Cueing study was intended to identify periods
   of driver fatigue via predictive algorithms formulated from the analysis of driver EEG data,
   in comparison to the objective performance measures, and in contrast with the (non-fatigued)
   Calibration driving session for the subject. Auditory Cueing extended the Baseline Driving
   paradigm by adding predictive and non-predictive (random) pre-perturbation onset audio cues and
   increasing the frequency and magnitude of perturbation events vs. baseline driving.
   Further information is available on request from `cancta.net <https://cancta.net>`__.
   
   **Methods**
   
   **Subjects:** Volunteers from the local community recruited through advertisements.
   **Apparatus:**  Driving simulator with steering wheel and brake / foot pedals (Real Time Technologies; Dearborn, MI);
   Video Refresh Rate (VRR) = 900 Hz; Vehicle data log file Sampling Rate (SR) = 100 Hz);
   EEG (BioSemi 64 (+8) channel systems with 4 eye and 2 mastoid channels recorded; SR=2048 Hz);
   Eye Tracking (Sensomotoric Instruments (SMI); REDEYE250).
   **Initial setup:** Upon arrival to the lab, subjects were given an introduction to the
   primary study for which they were recruited and provided informed consent and provided demographics information.
   This was followed by a practice session, to acclimate the subject to the driving simulator.
   The driving practice task lasted 10-15 min, until asymptotic performance in steering and speed control
   was demonstrated and lack of motion sickness was reported.
   Subjects were then outfitted and prepped for eye tracking and EEG acquisition.
   **Task organization within the study:** Subjects always began recording sessions by performing
   a Calibration Driving task, which was a 15-minute drive where the subject controlled only the steering
   (and speed was controlled by the simulator). Following this, subjects would perform Auditory Cueing
   condition A and Auditory Cueing condition B, with counter-balancing used across subjects as to
   which of them came first. This study only contains the Auditory Cueing portion of the study.
   **Auditory cueing task details:** Auditory Cueing A was 45 minutes of continuous driving,
   with subjects responsible for steering and maintaining speed, while a tone was played periodically at random.
   Auditory Cueing B was similar, but the tones were correlated with the onset of a perturbation event.
   Both driving tasks were conducted on the same simulated long, straight road.
   In each case, the subject was instructed to stay within the boundaries of the right-most lane,
   and to drive at the posted speed limits.
   The vehicle was periodically subject to lateral perturbing forces, which could be applied to
   either side of the vehicle, pushing the vehicle out of the center of the lane;
   and the subject was instructed to execute corrective steering actions to return the vehicle to the center of the lane.
   **Independent variables:** Auditory Cue (randomly presented before perturbation vs. predictive)
   **Dependent variables:** Reaction times to perturbations, continuous performance based on
   vehicle log (steering wheel angle, lane position, heading error, etc.),
   reaction times to target vehicles (police), Task-Induced Fatigue Scale (TIFS),
   Karolinska Sleepiness Scale (KSS), Visual Analog Scale of Fatigue (VAS-F).
   Note: Questionnaire data is available upon request from `cancta.net <https://cancta.net>`__.
   **Additional data acquired:** Participant Enrollment Questionnaire, Subject Questionnaire
   for Current Session, Simulator Sickness Questionnaire.
   **Experimental Location:** Teledyne Corporation, Durham, NC.
   **Note:** This dataset has a corresponding dataset in the BCIT Calibration Driving ds004118 which has the
   15 minute driving task performed prior to this one.


Highlights
----------

.. grid:: 1 2 3 3
   :gutter: 2

   .. grid-item-card:: Subjects & recordings
      :class-card: sd-border-1

      - Subjects: 17
      - Recordings: 34
      - Tasks: 1

   .. grid-item-card:: Channels & sampling rate
      :class-card: sd-border-1

      - Channels: 74
      - Sampling rate (Hz): 1024.0
      - Duration (hours): 0.0

   .. grid-item-card:: Tags
      :class-card: sd-border-1

      - Pathology: Healthy
      - Modality: Multisensory
      - Type: Attention

   .. grid-item-card:: Files & format
      :class-card: sd-border-1

      - Size on disk: 20.4 GB
      - File count: 34
      - Format: BIDS

   .. grid-item-card:: License & citation
      :class-card: sd-border-1

      - License: CC0
      - DOI: doi:10.18112/openneuro.ds004105.v1.0.0

   .. grid-item-card:: Provenance
      :class-card: sd-border-1

      - Source: openneuro
      - OpenNeuro: `ds004105 <https://openneuro.org/datasets/ds004105>`__
      - NeMAR: `ds004105 <https://nemar.org/dataexplorer/detail?dataset_id=ds004105>`__

Quickstart
----------

**Install**

.. code-block:: bash

    pip install eegdash

**Access the data**

.. code-block:: python

    from eegdash.dataset import DS004105

    dataset = DS004105(cache_dir="./data")
    # Get the raw object of the first recording
    raw = dataset.datasets[0].raw
    print(raw.info)

**Filter/query**

.. tab-set::

   .. tab-item:: Basic

      .. code-block:: python

         dataset = DS004105(cache_dir="./data", subject="01")

   .. tab-item:: Advanced

      .. code-block:: python

         dataset = DS004105(
             cache_dir="./data",
             query={"subject": {"$in": ["01", "02"]}},
         )


Quality & caveats
-----------------

- No dataset-specific caveats are listed in the available metadata.

API
---

.. currentmodule:: eegdash.dataset

.. autoclass:: eegdash.dataset.DS004105
   :members: __init__, save
   :show-inheritance:
   :member-order: bysource


See Also
--------

* :class:`eegdash.dataset.EEGDashDataset`
* :mod:`eegdash.dataset`
* `OpenNeuro dataset page <https://openneuro.org/datasets/ds004105>`__
* `NeMAR dataset page <https://nemar.org/dataexplorer/detail?dataset_id=ds004105>`__

