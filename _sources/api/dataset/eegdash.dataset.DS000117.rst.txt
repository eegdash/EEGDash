..
   This documentation page is generated during the Sphinx build.
   The underlying code is manually maintained and not autogenerated.

:html_theme.sidebar_secondary.remove:

DS000117
========

*Multisubject, multimodal face processing*

Access recordings and metadata through EEGDash.

**Citation:** Wakeman, DG, Henson, RN (2018). *Multisubject, multimodal face processing*. `10.18112/openneuro.ds000117.v1.1.0 <https://doi.org/10.18112/openneuro.ds000117.v1.1.0>`__

.. rst-class:: sd-badges

:bdg-primary-line:`Modality: meg` :bdg-secondary-line:`Subjects: 16` :bdg-secondary-line:`Recordings: 1156` :bdg-success-line:`License: CC0` :bdg-warning-line:`Source: openneuro` :bdg-info-line:`Citations: 77.0`

:bdg-success:`Metadata: Complete (100%)`

Quickstart
----------

.. tab-set::

   .. tab-item:: Get Started
      :sync: start

      **Install**

      .. code-block:: bash

         pip install eegdash

      **Access the data**

      .. code-block:: python

         from eegdash.dataset import DS000117

         dataset = DS000117(cache_dir="./data")
         # Get the raw object of the first recording
         raw = dataset.datasets[0].raw
         print(raw.info)

   .. tab-item:: Query & Filter
      :sync: query

      **Filter by subject**

      .. code-block:: python

         dataset = DS000117(cache_dir="./data", subject="01")

      **Advanced query**

      .. code-block:: python

         dataset = DS000117(
             cache_dir="./data",
             query={"subject": {"$in": ["01", "02"]}},
         )

      **Iterate recordings**

      .. code-block:: python

         for rec in dataset:
             print(rec.subject, rec.raw.info['sfreq'])

   .. tab-item:: Cite This Dataset
      :sync: cite

      If you use this dataset in your research, please cite the original authors.

      **BibTeX**

      .. code-block:: bibtex

         @dataset{ds000117,
           title = {Multisubject, multimodal face processing},
           author = {Wakeman, DG and Henson, RN},
           doi = {10.18112/openneuro.ds000117.v1.1.0},
           url = {https://doi.org/10.18112/openneuro.ds000117.v1.1.0},
         }


About This Dataset
------------------

This dataset was obtained from the OpenNeuro project (https://www.openneuro.org). Accession #: ds000117

The same dataset is also available here: ftp://ftp.mrc-cbu.cam.ac.uk/personal/rik.henson/wakemandg_hensonrn/, but in a non-BIDS format (which may be easier to download by subject rather than by modality)

Note that it is a subset of the data available on OpenfMRI (http://www.openfmri.org; Accession #: ds000117).


Description:  Multi-subject, multi-modal (sMRI+fMRI+MEG+EEG) neuroimaging dataset on face processing

Please cite the following reference if you use these data:

.. dropdown:: View full README
   :class-container: sd-shadow-sm

   This dataset was obtained from the OpenNeuro project (https://www.openneuro.org). Accession #: ds000117
   
   The same dataset is also available here: ftp://ftp.mrc-cbu.cam.ac.uk/personal/rik.henson/wakemandg_hensonrn/, but in a non-BIDS format (which may be easier to download by subject rather than by modality)
   
   Note that it is a subset of the data available on OpenfMRI (http://www.openfmri.org; Accession #: ds000117).
   
   
   Description:  Multi-subject, multi-modal (sMRI+fMRI+MEG+EEG) neuroimaging dataset on face processing
   
   Please cite the following reference if you use these data:
   
        Wakeman, D.G. & Henson, R.N. (2015). A multi-subject, multi-modal human neuroimaging dataset. Sci. Data 2:150001 doi: 10.1038/sdata.2015.1
   
   The data have been used in several publications including, for example:
   
      Henson, R.N., Abdulrahman, H., Flandin, G. & Litvak, V. (2019). Multimodal integration of M/EEG and f/MRI data in SPM12. Frontiers in Neuroscience, Methods, 13, 300.
   
       Henson, R.N., Wakeman, D.G., Litvak, V. & Friston, K.J. (2011). A Parametric Empirical Bayesian framework for the EEG/MEG inverse problem: generative models for multisubject and multimodal integration. Frontiers in Human Neuroscience, 5, 76, 1-16.
   
       Chapter 42 of the SPM12 manual (http://www.fil.ion.ucl.ac.uk/spm/doc/manual.pdf)
   
   (see ftp://ftp.mrc-cbu.cam.ac.uk/personal/rik.henson/wakemandg_hensonrn/Publications for full list), as well as the BioMag2010 data competition and the Kaggle competition: https://www.kaggle.com/c/decoding-the-human-brain)
   
   
   
   **func/**
   
   Unlike in v1-v3 of this dataset, the first two (dummy) volumes have now been removed (as stated in \*.json), so event onset times correctly refer to t=0 at start of third volume 
   
   Note that, owing to scanner error, Subject 10 only has 170 volumes in last run (Run 9) 
   
   
   **meg/**
   
   Three anatomical fiducials were digitized for aligning the MEG with the MRI: the nasion 
   (lowest depression between the eyes) and the left and right ears (lowest depression 
   between the tragus and the helix, above the tragus). This procedure is illustrated here:
   http://neuroimage.usc.edu/brainstorm/CoordinateSystems#Subject_Coordinate_System\_.28SCS\_.2F_CTF.29
   and in task-facerecognition_fidinfo.pdf 
   
   The following triggers are included in the .fif files and are also used in the “trigger” column of the meg and bold events files:
   
   Trigger            Label               Simplified Label
   
   5         Initial Famous Face               IniFF
   6         Immediate Repeat Famous Face      ImmFF
   7         Delayed Repeat Famous Face        DelFF
   13        Initial Unfamiliar Face           IniUF
   14        Immediate Repeat Unfamiliar Face  ImmUF
   15        Delayed Repeat Unfamiliar Face    DelUF
   17        Initial Scrambled Face            IniSF
   18        Immediate Repeat Scrambled Face   ImmSF
   19        Delayed Repeat Scrambled Face     DelSF
   
   
   **stimuli/meg/**
   
   The .bmp files correspond to those described in the text. There are 6 additional images in this directory, which were used in the practice experiment to familiarize participants with the task (hence some more BIDS validator warnings)
   
   
   **stimuli/mri/**
   
   The .bmp files correspond to those described in the text.
   	
   
   **Defacing**
   
   Defacing of MPRAGE T1 images was performed by the submitter. A subset of subjects have given consent for non-defaced versions to be shared - in which case, please contact rik.henson@mrc-cbu.cam.ac.uk.
    
   
   **Quality Control**
   
   Mriqc was run on the dataset. Results are located in derivatives/mriqc. Learn more about it here: https://mriqc.readthedocs.io/en/latest/
    
   
   **Known Issues**
   
   N/A
   
   
   **Relationship of Subject Numbering relative to other versions of Dataset**
   
   
   There are multiple versions of the dataset available on the web (see notes above), and these entailed a renumbering of the subjects for various reasons. Here are all the versions and how to match subjects between them (plus some rationale and history for different versions):
    
   1. Original Paper (N=19): Wakeman & Henson (2015): doi:10.1038/sdata.2015.1 
       Number refers to order that tested (and some, eg 4, 7, 13 etc were excluded for not completing both MRI and MEG sessions)
    
   2. openfMRI, renumbered from paper: http://openfmri.org/s3-browser/?prefix=ds000117/ds000117_R0.1.1/uncompressed/
       Numbers 1-19 just made contiguous
    
   3. FTP subset of N=16: ftp: ftp://ftp.mrc-cbu.cam.ac.uk/personal/rik.henson/wakemandg_hensonrn/  
       This set was used for SPM Courses
       Designed to illustrate multimodal integration, so wanted good MRI+MEG+EEG data for all subjects
       Removed original subject_01 and subject_06 because bad EEG data; subject_19 because poor EEG and fMRI data
       (And renumbered subject_14 for some reason).
    
   4. Current OpenNeuro subset N=16 used for (BIDS): https://openneuro.org/datasets/ds000117 
       OpenNeuro was rebranding of openfMRI, and enforced BIDS format
       Since this version designed to illustrate multi-modal BIDS, kept same numbering as FTP
    
   W&H2015       openfMRI    FTP      openNeuro
   ========       ======        ===     =======
   subject_01      sub001
   subject_02      sub002      Sub01   sub-01
   subject_03      sub003      Sub02   sub-02
   subject_05      sub004      Sub03   sub-03
   subject_06      sub005
   subject_08      sub006      Sub05   sub-05
   subject_09      sub007      Sub06   sub-06
   subject_10      sub008      Sub07   sub-07
   subject_11      sub009      Sub08   sub-08
   subject_12      sub010      Sub09   sub-09
   subject_14      sub011      Sub04   sub-04
   subject_15      sub012      Sub10   sub-10
   subject_16      sub013      Sub11   sub-11
   subject_17      sub014      Sub12   sub-12
   subject_18      sub015      Sub13   sub-13
   subject_19      sub016
   subject_23      sub017      Sub14   sub-14
   subject_24      sub018      Sub15   sub-15
   subject_25      sub019      Sub16   sub-16


Dataset Information
-------------------

.. list-table::
   :widths: 25 75
   :header-rows: 0

   * - Dataset ID
     - ``DS000117``
   * - Title
     - Multisubject, multimodal face processing
   * - Year
     - 2018
   * - Authors
     - Wakeman, DG, Henson, RN
   * - License
     - CC0
   * - Citation / DOI
     - `doi:10.18112/openneuro.ds000117.v1.1.0 <https://doi.org/10.18112/openneuro.ds000117.v1.1.0>`__
   * - Source links
     - `OpenNeuro <https://openneuro.org/datasets/ds000117>`__ | `NeMAR <https://nemar.org/dataexplorer/detail?dataset_id=ds000117>`__ | `Source URL <https://openneuro.org/datasets/ds000117/versions/1.1.0>`__

.. dropdown:: Copy-paste BibTeX
   :class-container: sd-shadow-sm
   :class-title: sd-bg-light

   .. code-block:: bibtex

      @dataset{ds000117,
        title = {Multisubject, multimodal face processing},
        author = {Wakeman, DG and Henson, RN},
        doi = {10.18112/openneuro.ds000117.v1.1.0},
        url = {https://doi.org/10.18112/openneuro.ds000117.v1.1.0},
      }

.. admonition:: Found an issue with this dataset?
   :class: tip

   If you encounter any problems with this dataset (missing files, incorrect metadata,
   loading errors, etc.), please let us know!

   .. button-link:: https://github.com/eegdash/EEGDash/issues/new?title=%5BDataset%5D%20Issue%20with%20DS000117&body=%23%23%20Dataset%0A%0A-%20%2A%2ADataset%20ID%3A%2A%2A%20DS000117%0A-%20%2A%2ATitle%3A%2A%2A%20Multisubject%2C%20multimodal%20face%20processing%0A%0A%23%23%20Issue%20Description%0A%0APlease%20describe%20the%20issue%20you%20encountered%20with%20this%20dataset%3A%0A%0A%23%23%20Steps%20to%20Reproduce%0A%0A1.%20%0A2.%20%0A3.%20%0A%0A%23%23%20Expected%20Behavior%0A%0A%0A%23%23%20Additional%20Context%0A%0A&labels=dataset
      :color: primary
      :outline:

      Report an Issue on GitHub

Technical Details
-----------------

.. grid:: 1 2 3 3
   :gutter: 2

   .. grid-item-card:: Subjects & recordings
      :class-card: sd-border-1 highlight-primary

      - Subjects: 16
      - Recordings: 1156
      - Tasks: 2

   .. grid-item-card:: Channels & sampling rate
      :class-card: sd-border-1 highlight-secondary

      - Channels: 394
      - Sampling rate (Hz): 1100.0
      - Duration (hours): 0.0

   .. grid-item-card:: Tags
      :class-card: sd-border-1 highlight-tertiary

      - Pathology: Healthy
      - Modality: Visual
      - Type: Perception

   .. grid-item-card:: Files & format
      :class-card: sd-border-1

      - Size on disk: 87.6 GB
      - File count: 1156
      - Format: BIDS

   .. grid-item-card:: License & citation
      :class-card: sd-border-1

      - License: CC0
      - DOI: doi:10.18112/openneuro.ds000117.v1.1.0

   .. grid-item-card:: Provenance
      :class-card: sd-border-1

      - Source: openneuro
      - OpenNeuro: `ds000117 <https://openneuro.org/datasets/ds000117>`__
      - NeMAR: `ds000117 <https://nemar.org/dataexplorer/detail?dataset_id=ds000117>`__

API Reference
-------------

Use the ``DS000117`` class to access this dataset programmatically.

.. currentmodule:: eegdash.dataset

.. autoclass:: eegdash.dataset.DS000117
   :members: __init__, save
   :show-inheritance:
   :member-order: bysource


See Also
--------

* :class:`eegdash.dataset.EEGDashDataset`
* :mod:`eegdash.dataset`
* `OpenNeuro dataset page <https://openneuro.org/datasets/ds000117>`__
* `NeMAR dataset page <https://nemar.org/dataexplorer/detail?dataset_id=ds000117>`__

